{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Matthew\\\\Documents\\\\CS4375'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#os.chdir('C:\\\\Users\\Matthew...')\n",
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('penguins_size.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 334 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            334 non-null    object \n",
      " 1   island             334 non-null    object \n",
      " 2   culmen_length_mm   334 non-null    float64\n",
      " 3   culmen_depth_mm    334 non-null    float64\n",
      " 4   flipper_length_mm  334 non-null    float64\n",
      " 5   body_mass_g        334 non-null    float64\n",
      " 6   sex                334 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "#Drop the non applicable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 334 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            334 non-null    object \n",
      " 1   island             334 non-null    object \n",
      " 2   culmen_length_mm   334 non-null    float64\n",
      " 3   culmen_depth_mm    334 non-null    float64\n",
      " 4   flipper_length_mm  334 non-null    float64\n",
      " 5   body_mass_g        334 non-null    float64\n",
      " 6   sex                334 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop(\"species\", axis=1),drop_first=True)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=(0.3),random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, default=None\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization accuracy.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int or RandomState, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0, 1)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : DecisionTreeClassifier\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier, ExtraTreesClassifier\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(...)\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest.\n",
      " |      The class probability of a single tree is the fraction of samples of\n",
      " |      the same class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)\n",
    "#read about it, default criteria is gini, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, max_features = \"auto\", random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=101)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39,  2,  0],\n",
       "       [ 1, 22,  0],\n",
       "       [ 0,  0, 37]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x22b7fbafbb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31867744, 0.1018487 , 0.17343398, 0.21316964, 0.14512091,\n",
       "       0.03720114, 0.00632264, 0.00422556])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <td>0.318677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <td>0.101849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <td>0.173434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_mass_g</th>\n",
       "      <td>0.213170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>island_Dream</th>\n",
       "      <td>0.145121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>island_Torgersen</th>\n",
       "      <td>0.037201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_FEMALE</th>\n",
       "      <td>0.006323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_MALE</th>\n",
       "      <td>0.004226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature Importance\n",
       "culmen_length_mm             0.318677\n",
       "culmen_depth_mm              0.101849\n",
       "flipper_length_mm            0.173434\n",
       "body_mass_g                  0.213170\n",
       "island_Dream                 0.145121\n",
       "island_Torgersen             0.037201\n",
       "sex_FEMALE                   0.006323\n",
       "sex_MALE                     0.004226"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index=X.columns,data = model.feature_importances_, columns=[\"Feature Importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = []\n",
    "\n",
    "for n in range(1, 40):\n",
    "    #Use n random trees\n",
    "    model = RandomForestClassifier(n_estimators=n, max_features = \"auto\")\n",
    "    model.fit(X_train,y_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_error.append(1-accuracy_score(test_preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22b063f0c70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtHElEQVR4nO3dfXRc9Xng8e+jGY1ebcsjBBi/aQwuYDAYMBJJumlJA7FpiOmedkNempbTPRw2wKbZzTb0ZE832f6x2ZxN09IQCEkooc0G0jQ0bso2yTY4hCVItjH4FTvCY2xhYxuNZFuSpdHLs3/MvaPxeEZzZ3THM7rzfM7RsWbu22+uZx795vm9iapijDEmuOoqXQBjjDHlZYHeGGMCzgK9McYEnAV6Y4wJOAv0xhgTcOFKFyCXiy66SDs7OytdDGOMmTe2b9/+jqp25NpWlYG+s7OTbdu2VboYxhgzb4jIm/m2WerGGGMCzgK9McYEnAV6Y4wJOE85ehHZAPwVEAK+qapfzNouzvY7gFHgD1X1FRG5EngmY9dVwJ+p6l/6UHZjzDwzMTFBf38/Y2NjlS7KvNXY2MiyZcuor6/3fEzBQC8iIeAR4DagH9gqIptVdW/GbhuB1c5PN/Ao0K2q+4F1Ged5C3jWc+mMMYHS39/PggUL6OzsJFU/NMVQVQYGBujv7ycWi3k+zkvqpgvoU9WDqpoEngY2Ze2zCXhKU14G2kRkSdY+vwW8oap5W4aNMcE2NjZGe3u7BfkSiQjt7e1FfyPyEuiXAkcyHvc7zxW7z93Ad/NdRETuFZFtIrLt5MmTHopljJmPLMjPTSn3z0ugz3XW7LmNZ91HRCLAh4C/z3cRVX1cVder6vqOjpx9/ufs+f0nOJIYLcu5jTGmWnkJ9P3A8ozHy4CjRe6zEXhFVY+XUkg/qCr/4e+28+RLhypVBGNMBQ0MDLBu3TrWrVvHpZdeytKlS9OPk8lkweO3bNnCSy+9lHPbk08+SUdHR/p869atY+/evTn3rQQvvW62AqtFJEaqMfVu4KNZ+2wGHhCRp0k1xp5S1WMZ2z/CLGmbC2F4fJKxiWnOjE1UshjGmAppb2/n1VdfBeDzn/88ra2tfOYzn/F8/JYtW2htbeXd7353zu0f/vCH+epXv5r3+KmpKUKhUN7H+UxOThIOz20Sg4I1elWdBB4AfgzsA76nqntE5D4Ruc/Z7TngINAHfAP4pHu8iDST6rHzgzmVdI4SI6m/2CPJqUoWwxhTRbZv385v/MZvcNNNN/GBD3yAY8dS9dOHH36YNWvWcN1113H33Xdz6NAhHnvsMb7yla+wbt06fvGLX3g6/5YtW7j11lv56Ec/ytq1a897PDY2xj333MPatWu54YYbeP7554HUN4Tf+73f48477+T222+f8+v09GdCVZ8jFcwzn3ss43cF7s9z7CjQPocy+mLADfTjkxUuiTEG4Av/tIe9R0/7es41ly3kv915jad9VZUHH3yQH/7wh3R0dPDMM8/wuc99jieeeIIvfvGLxONxGhoaGBoaoq2tjfvuu2/WbwHPPPMML774YvrxL3/5SwB6e3vZvXs3sViMLVu2nPP4y1/+MgC7du3i9ddf5/bbb+fAgQPp43fu3Ek0Gp3LLQGqdFKzchh0Av3ouNXojTEwPj7O7t27ue2224BUKmXJklSv8Ouuu46Pfexj3HXXXdx1112ezpcvddPV1XVOn/fMxy+++CIPPvggAFdddRUrV65MB/rbbrvNlyAPNRTo3Rr9sNXojakKXmve5aKqXHPNNemad6Z//ud/5oUXXmDz5s38+Z//OXv27Cn5Oi0tLXkfp5Ih3o6bi5qZ68bN0Y8mLdAbY6ChoYGTJ0+mA/3ExAR79uxhenqaI0eOcOutt/KlL32JoaEhhoeHWbBgAWfOnPG1DO9973v5zne+A8CBAwc4fPgwV155pa/XgBoM9MOWujHGAHV1dXz/+9/ns5/9LNdffz3r1q3jpZdeYmpqio9//OPpBtJPf/rTtLW1ceedd/Lss8/mbYx95plnzulema8rZqZPfvKTTE1NsXbtWj784Q/z5JNP0tDQ4Ptrldm+OlTK+vXr1e+FRz7z96/x/e39NEdC7P3vG3w9tzHGm3379nH11VdXuhjzXq77KCLbVXV9rv1rrkY/mpxierr6/rgZY0y51EygdxtjAUYnLH1jjKkdNRPoEyPj6d9HreeNMRVTjeni+aSU+1czgX5wZIL2lghgXSyNqZTGxkYGBgYs2JfInY++sbGxqONqoh/9+OQUw+OTXH5xGwMjSUZtGgRjKmLZsmX09/djU5GXzl1hqhg1Eejdhtjli5t47ciQ1eiNqZD6+vqiVkYy/qiJ1M3AsBPoo82ADZoyxtSWmgj0g6OpQL/CCfQ2aMoYU0tqItDPpG6cGr2lbowxNaQmAv1M6qYJsDnpjTG1pSYCfWIkSZ3AkkVOoLcavTGmhtRGoB9Nsrg5QiRcR0O4jhFrjDXG1JDaCPTDSaLOYKmWhrDV6I0xNaU2Av1IksXpQB+yVaaMMTWlJgL9wMh4evqDlkjYBkwZY2pKTQT6wdGJc1I3NgWCMaaWBD7QT00rg6PJdI2+ORKyGr0xpqYEPtAPjSZRJZ2jb20I2xQIxpiaEvhA746KjaZr9GFGrDHWGFNDPAV6EdkgIvtFpE9EHsqxXUTkYWf7ThG5MWNbm4h8X0ReF5F9IvIuP19AIW6gb29JLbjb2hCyfvTGmJpSMNCLSAh4BNgIrAE+IiJrsnbbCKx2fu4FHs3Y9lfAv6jqVcD1wD4fyu3ZeTX6hrB1rzTG1BQvNfouoE9VD6pqEnga2JS1zybgKU15GWgTkSUishB4L/AtAFVNquqQf8UvbCAr0LdEQiSnpklOTl/IYhhjTMV4CfRLgSMZj/ud57zsswo4CfyNiOwQkW+KSEuui4jIvSKyTUS2+bn6jFujX9xSD6S6V4LNSW+MqR1eAr3keC57wcd8+4SBG4FHVfUGYAQ4L8cPoKqPq+p6VV3f0dHhoVjeJEaSLGgI0xAOAakBU2DrxhpjaoeXQN8PLM94vAw46nGffqBfVXuc579PKvBfMImRJNHWSPrxTI3e8vTGmNrgJdBvBVaLSExEIsDdwOasfTYDn3B639wCnFLVY6r6NnBERK509vstYK9fhfciMZKaudLV3JCq2VuN3hhTKwouDq6qkyLyAPBjIAQ8oap7ROQ+Z/tjwHPAHUAfMArck3GKB4HvOH8kDmZtK7uBkSSXLWpMP251a/TW88YYUyMKBnoAVX2OVDDPfO6xjN8VuD/Psa8C60sv4twMjiS59rKF6cfNEavRG2NqS6BHxqrqeTn6Vut1Y4ypMYEO9MPjkySnpolm5uidXje2bqwxplYEOtBnj4qF1MIjYOvGGmNqR00E+vaM1E1TfQgRGLVAb4ypETUR6KPOhGYAIuKsMmWpG2NMbQh0oE/Pc5ORowdn3VhrjDXG1IhAB/p0jb41K9DburHGmBoS6EA/OJIkEq6jxek777J1Y40xtSTQgX5gJLVWrMi5c67ZurHGmFoS6ECfPc+Ny9aNNcbUkkAH+oGR5DldK13NDbZurDGmdgQ60A+OJM8ZLOVqiYRswJQxpmYEOtAn8gV6a4w1xtSQwAb68ckphscnz+tDD06NPjlJatJNY4wJtsAG+nx96CFVo1eFsxNWqzfGBF/gA317jtRNc4OtG2uMqR2BD/SZ89y4Wp0ZLG2VKWNMLaiBQF9/3jZ3Tnqr0RtjakFgA/3A8Gw1eneVKavRG2OCL7CBfnA0SZ1AW1OuGr0tPmKMqR2BDfQDzvQHdXVy3raWBnc5QQv0xpjgC2ygTwwnWZyjxw3MBHprjDXG1ILgBvrR3KNigfS0xdYYa4ypBcEN9M4Uxbm4vW5sBktjTC3wFOhFZIOI7BeRPhF5KMd2EZGHne07ReTGjG2HRGSXiLwqItv8LPxs8s1zAxAJ1xEJ1dm6scaYmhAutIOIhIBHgNuAfmCriGxW1b0Zu20EVjs/3cCjzr+uW1X1Hd9KXcDUtDI4S+oGbN1YY0zt8FKj7wL6VPWgqiaBp4FNWftsAp7SlJeBNhFZ4nNZPTt1dgJVZg30zbZurDGmRngJ9EuBIxmP+53nvO6jwE9EZLuI3JvvIiJyr4hsE5FtJ0+e9FCs/BIj48Dsgb61IWy9bowxNcFLoD+/I3oqeHvd5z2qeiOp9M79IvLeXBdR1cdVdb2qru/o6PBQrPzcUbHtOUbFupobQtaP3hhTE7wE+n5gecbjZcBRr/uoqvvvCeBZUqmgsnLnuVmcY54bV0skbCNjjTE1wUug3wqsFpGYiESAu4HNWftsBj7h9L65BTilqsdEpEVEFgCISAtwO7Dbx/LnlBgtXKNvaQjZurHGmJpQsNeNqk6KyAPAj4EQ8ISq7hGR+5ztjwHPAXcAfcAocI9z+CXAsyLiXut/q+q/+P4qsiSGPdboLXVjjKkBBQM9gKo+RyqYZz73WMbvCtyf47iDwPVzLGPRBkaSLGgI0xAO5d3H1o01xtSKQI6MTYzkn+fG1dwQsu6VxpiaEMhAX2iwFEBrJExycpqJqekLVCpjjKmMQAb6geH889y4mm0GS2NMjQhkoJ9tnhuXu26sNcgaY4IucIFeVT0FencGS+tLb4wJusAF+pHkFMmp6YKBviVdo7fUjTEm2AIX6BPpRcELBHqr0RtjakTgAv2AM6FZe2uhGr0FemNMbQhcoE/Pc9PsLdDboCljTNAFNtDPNs8N2LqxxpjaEdhAH/WYurFVpowxQRfIQB8J16Vr7Pk01bs1ekvdGGOCLXCBfmAkSbQ5gjNjZl51dUJLJMSopW6MMQEXuEA/6GGwlKu5waYqNsYEX+AC/cBIsmDXSldLxBYfMcYEX+ACvZfpD1wtDbacoDEm+AIZ6Av1oXfZKlPGmFoQqEA/PjnF8PhkwSmKXbZurDGmFgQq0A+OTACF+9C7rDHWGFMLAhXo0/PceKzRt0bCtvCIMSbwAhXovc5z42puCFljrDEm8AIZ6L12r2x1UjeqWs5iGWNMRQUy0EcLTGjmao6EmVYYm7AFwo0xwRW4QF8nsKip3tP+LbZurDGmBgQq0A+MJGlrjhCqm32eG5etMmWMqQWeAr2IbBCR/SLSJyIP5dguIvKws32niNyYtT0kIjtE5Ed+FTyXYua5gYwavfW8McYEWMFALyIh4BFgI7AG+IiIrMnabSOw2vm5F3g0a/ungH1zLm0BA0UHeqdGb6kbY0yAeanRdwF9qnpQVZPA08CmrH02AU9pystAm4gsARCRZcBvA9/0sdw5JUaSnvvQQ6oxFix1Y4wJNi+BfilwJONxv/Oc133+EvgTYNauLSJyr4hsE5FtJ0+e9FCs8yVGkiwuItC32rqxxpga4CXQ52rZzO54nnMfEfkgcEJVtxe6iKo+rqrrVXV9R0eHh2KddzxL25qItbd4PqbZ1o01xtSAsId9+oHlGY+XAUc97vO7wIdE5A6gEVgoIn+nqh8vvci5iQj/9OCvF3VMukZvgd4YE2BeavRbgdUiEhORCHA3sDlrn83AJ5zeN7cAp1T1mKr+qaouU9VO57iflSPIl6o53Y/eUjfGmOAqWKNX1UkReQD4MRACnlDVPSJyn7P9MeA54A6gDxgF7ilfkf0TCdURrhNrjDXGBJqX1A2q+hypYJ753GMZvytwf4FzbAG2FF3CMhIRW2XKGBN4gRoZW4qWSMhSN8aYQLNAbzV6Y0zA1XygT60yZTV6Y0xw1Xygb7XFR4wxAVfzgb45YqkbY0yw1Xygb20I2xQIxphAq/lA3xyx1I0xJthqPtC3OOvGGmNMUFmgj4QZm5hmcsrWjTXGBJMFeme+m9EJy9MbY4LJAn2DLT5ijAm2mg/07pz0tm6sMSaoaj7Qt1qN3hgTcDUf6NPrxlrPG2NMQNV8oJ9ZZcpSN8aYYKr5QD+zypTV6I0xwVTzgb7FTd1Yjd4YE1AW6N0avTXGGmMCquYDvTXGGmOCruYDfahOaKq3ic2MMcFV84EeUukbW2XKGBNUFuixdWONMcFmgR53lSmr0RtjgskCPbZurDEm2DwFehHZICL7RaRPRB7KsV1E5GFn+04RudF5vlFEekXkNRHZIyJf8PsF+KE5EmbUet0YYwKqYKAXkRDwCLARWAN8RETWZO22EVjt/NwLPOo8Pw68T1WvB9YBG0TkFn+K7h9rjDXGBJmXGn0X0KeqB1U1CTwNbMraZxPwlKa8DLSJyBLn8bCzT73zo34V3i8tEWuMNcYEl5dAvxQ4kvG433nO0z4iEhKRV4ETwE9VtSfXRUTkXhHZJiLbTp486bH4/rBeN8aYIPMS6CXHc9m18rz7qOqUqq4DlgFdInJtrouo6uOqul5V13d0dHgoln/c1I1q1X3ZMMaYOfMS6PuB5RmPlwFHi91HVYeALcCGYgtZbs2RMFPTyvikLRBujAkeL4F+K7BaRGIiEgHuBjZn7bMZ+ITT++YW4JSqHhORDhFpAxCRJuD9wOv+Fd8ftsqUMSbIwoV2UNVJEXkA+DEQAp5Q1T0icp+z/THgOeAOoA8YBe5xDl8CfNvpuVMHfE9Vf+T/y5gbd93Y0eQU7RUuizHG+K1goAdQ1edIBfPM5x7L+F2B+3MctxO4YY5lLDu3Rj9sNXpjTADZyFig2V1O0AZNGWMCyAI90BJxFx+xQVPGmOCxQE+qHz1YY6wxJpgs0JOxbqxNg2CMCSAL9Ni6scaYYLNAT0bqxhpjjTEBZIEeaAjXEaoTq9EbYwLJAj0gIjRHQtbrxhgTSBboHa02g6UxJqAs0DuaIyFGrdeNMSaALNA7WhrCNgWCMSaQLNA7WmzdWGNMQFmgd7Q0WGOsMSaYLNA7WhrC1o/eGBNIFugdzZGw1eiNMYFkgd7R2hCy7pXGmECyQO9ojoQ5OzHF1LQtEG6MCRYL9I5WW3zEGBNQFugdzQ0z68YaY0yQWKB3uHPS26ApY0zQWKB3uFMVj1rPG2NMwFigd7jrxlqN3hgTNBboHS3WGGuMCSgL9I70coLWGGuMCRhPgV5ENojIfhHpE5GHcmwXEXnY2b5TRG50nl8uIs+LyD4R2SMin/L7BfglvZygpW6MMQFTMNCLSAh4BNgIrAE+IiJrsnbbCKx2fu4FHnWenwT+s6peDdwC3J/j2KrQHLFAb4wJJi81+i6gT1UPqmoSeBrYlLXPJuApTXkZaBORJap6TFVfAVDVM8A+YKmP5feN2xhr890YY4Im7GGfpcCRjMf9QLeHfZYCx9wnRKQTuAHoyXUREbmX1LcBVqxY4aFY/gqH6mgI183rGSy//JP9XL1kIXesXVLS8V/56QGuuLiVO6+/zOeSpXz1Z79i6eImfueGZWU5fyGPv/AGi5rq+fDN5Xl/PfFinPpwHb9/y8qynL+Qb790iH989a05neP9V1/C/bde4VOJzvX97f0cPz1WtvMXsvm1oxw8Ocwfv//XKnL9SvJSo5ccz2VPCDPrPiLSCvwD8MeqejrXRVT1cVVdr6rrOzo6PBTLfyuizRw4fqYi156r4fFJvrblDb71Yryk488mp/jalj6++YuDPpcsZXxyir/+WR9f/3l5zl/I1LTy1//ax6Nb3ijL+VWVrz7fx9ee70P1ws+XpKp8/edv8PapMVobwiX9vDM8ztd//kbZ5nv6+s/f4JHn+5iYmi7L+Qv5xgsH+drzbzA2UXvf2r3U6PuB5RmPlwFHve4jIvWkgvx3VPUHpRe1/LpiUX746lGmppVQXa6/XdVr+5uDTE0rO/uHOJucoslJRXm14/AgE1PK7qOnGR6fTM/945dd/acYn5xm//EzDI0maWuO+Hr+QvYdO82Z8UnOjE9y/PQYlyxs9PX8fSeGSYwkAegfPMvyaLOv5y+kf/AsR0+N8YUPXcMfvLuzpHM8u6OfTz/zGvvfPsOayxb6Wr6B4XF+dWIYgN1vneKGFYt9PX8hZ8Ym2HP0FNMKOw4P8a7L2y/o9SvNS41+K7BaRGIiEgHuBjZn7bMZ+ITT++YW4JSqHhMRAb4F7FPVv/C15GXQFYsyPD7J3qM5v3RUtd74AAATU8qOI4NFH98TTwCpmu8rbxZ/vNfzq8K2Q/6fv5Be5/rZv/ulJ+OcPWU4fyHua+qKRUs+R1es3TnXgC9lyrQ14/+8HPe/kO1vDuJ+UanE9SutYKBX1UngAeDHpBpTv6eqe0TkPhG5z9ntOeAg0Ad8A/ik8/x7gN8H3icirzo/d/j9Ivzifkh6yvBGL7feeIIrLm6lTkp7I/fGE6zqaCFcJ2X5IPTGE3S2NxMJ19F7qDKBcGlbE60N4bK9vosXNNDWXF+WQOnl+oua6rnykgUln2NpWxNL25rK8v/TG0/QWF/HimhzRQJtbzxBuE5Y1dFC76H59/meK0/fz1X1OVLBPPO5xzJ+V+D+HMe9SO78fVVasqgp/Ub89/9mVaWL49nYxBSvHTnFPe/ppLG+jp6DxX2QxieneOXwIB/rXskrhwd9/0M3OTXN9jcHueuGyzhwfJiegxf2g6aq9B5KcOuVF/PO8Ljvr09V6Y0n6F7VztjEVEUCWU98gJs7o9TNMeXYvSrKCwdOoqqkvpD7oyc+wI0rFrOyvZkf7Tx2wdOjvfEEa5ctYt3yNr7be5jk5DSRcO2MF62dV+pRdyzK1kMJpufRAiQ7Dg+RnJqmKxalq7OdVw4Pkpz03uDl5s+7YlG6Y1FeO3LK1warvcdSef+uWDvdsWi6HeBCcfPn3bEoXbEoB47P5NP9cDgxytunx9L379DAKMdPj/l2/kKOnx7j0MAo3XNI27i6Y1HeGU7yxskRH0qWcnpsgr3HTqfen7EoZ8Ymef3tC5cePZuc4rX+ofT/z9jENLveOnXBrl8NLNBn6YpFGRydSDcczQe98QQisH5l6oM0PjnNrreGPB/v5pRv7lxMVyxKcmqaV494P95L+QC6OlPlK1c7QD49GflrNxhu9TE94Z7f/UOS+dyF4Ed+3jWTp/ev/NsPDaKKE+j9P38hO46kOhp0x6Lc3Bm94NevBhbos3SXsUGqXHoPDXDVpQtZ1FxfUqDpjSdYfXEr7a0NrO+MIiXm+fPpiSdY2d7MpYsauXHFYkJlagfIx82fr2xvZu2yRTSE63y9fm88weLmeq7oaGXNkoVOO8CFe//0xhM0R0Jc40NPmc72ZjoWNPha/p54gvqQcMPyxTPtABf4/18EbloZpb21gSsubp1Xn28/WKDPsjzaxKULGyvSc6IUyclU/tutqUZbIvzaJa2e8/STU9NsO5Sge1Xq+EVN9Vx96ULf8tjT08rWQ4l0+VoawqxduuiCNXirKj3xAbpXtSMiNIRD3Lhisa/X740n6Iql8uPhUB03rVx8QQNZT3yAm1YuJhya+8dZROiKRemJJ3wbD9ATH+D6ZW3pLr/dq6L0+nj+QnrjCdYsWciipvrU9WNRth0arKn1oS3QZxGRC/5GnItdb51ibGL6nPxsVyzK9jcHmfQwMGXvsdOMJKfSX6kzjy8mz5/Pr04MMzQ6cc75y9EOkM/hxCjHT4+fk9boikXZe/Q0p8cm5nz+Y6fOcjgxet7987sdIJ/ESJIDx4e5ZZV//cJviUU5dmqM/sGzcz7XaHKSXf2nzrn/3bEoAyP+tgPkk5yc5pXDg+f9/58Zn2TfsfnXjbpUFuhz6IpFOXFmnDcHRitdlILcmuPN57yR2xken2TfscKjfDPz5y63wWr30bk3WLk15+w/RH63A+S//kz+3NUdizKtqb7Vc9Wb5/yZ28rJbWvwIz/vcv9o+fGtdsfhISanNSvQuucv/7e6XW8N5awIpa4/P761+8ECfQ7d6TdC9efxeuMDXN7RwkWtDenniil/Zv7cdbOPgaonnmDJokaWLW5KP1eOdoB8MvPnrhtWLKY+5E87QU88wYKGMFcvmcmPl6MdIJ/eeIJIuI7rli3y7ZyrL271bTxATzxBncBNK2dGws60A5T//sx0NJgJ9DPdqKv/8+0XC/Q5XN7RSntLpOr/4k9NK9sODdKd9bX9koWNdLYXHpiSnT93XdTawOUdLXP+IKb7l8ei5/TJdtsBLlQgdPPnrqZIiOuWtfly/d54gvWdi8/pE+62A1yIgTm98QQ3LG+jIVzclBezqasTbu6M+nR/Brh26SIWNNannxMRumNReg6WPz2a2dEgU3ds/qRn/WCBPge3Qarau2C587fk6j/dFYvSW2A8wIETZ87Ln7u6V7WzNZ6YU4PVoYFRTp4Zz3l+tx2gnBNc5cqfZ17fnReoVO8Mj9N3Yjjv+f1qB8jntDN/S/Yfej/4MR5gfHKKHYeHzkkLZp7/7dP+tAPk41aEcqW15mM36rmwQJ9HVyxK/+BZ3hoq3xtxrnJ9LXV1xdoZKvBGzpVfdnX70GDljoDN9UHrjkU5OzFV1oErs72+rlg0NS/Q4dLz9Ftn6b+ebgco47w+7vwtfgyUytbtQ55+Z8ZAvGzuH8eXyzhKeu9Rd6Berv8f/9oh5gML9Hl0pfPU1ZvH640PsDzaxGVtTedt6/ZQ/lz5c5cfA0t64wkuao1weUfL+ee/AA2WufLnrvUrF1Mnc/ug9zjzt6xden5+3G0HKGcgcedvuWFFm+/nvnrJgjmPB+idpSIy0w5Qzv9/tyPA+d943G7U1f6t3S8W6PO46tKFLGgszwRYfpjJf+f+2r5scROXLco/HiBf/tx1WVsTy6NzG9jS4+THc53/ovTAlfIGwuz8uWtBYz3XXLZozn/Iblq5OOecKTPtAOWrKLjzt7jLYPrJj/EAPfEEV126gMUt509JXVcndHVGyzrBXW+OjgaumW7UAzWRp7dAn0fIeSNW61e7X50YZnB0Im+3ukIDX+LvjOTNn7u6OtvpPVRag1X/4ChvDZ3NmZ9Nnz8WnXM7QD6z5c8zr//K4UHGJ4vP0586O8G+t0/T1Tn7+Xf2n5pTO0A+Z5NT7OwfyvuH3g/dq0ofDzA5Nc32Q4lZu312xaK8OTDK26f8nxfI7WhQ6P13/PT86EY9VxboZ9EVi3LwZCogVptc/cOzdcXaOXlmnEM53she5kfpXhUlMZKkr4QGq5n+3fkDkR/tAHmv7+H1pecF6i++nWD7m4n0/C2znX9yem7tAPm4C8WUIz/vmst4gD1H3YF4s7y/3OlGylCr7zs5e0Uodf3amffGAv0s3DeJnxNg+aU3nuCShQ2smGUlo9naGWbLn7tm+uMX//p7DiZY2Bjmykvzz4/eVcYP2mz5c5ebOy719UVCdbPmx912gJfL9PpE4KbO8q3UtHZpW8njAbxUJNx2gHJMW+2ec7ZvPPOlG7UfLNDP4tqli2iOhC74/OmFpPLrA3TH2medMzw1kCr3G3m2/LlrRbSZSxaWNrDF7b8+25zjmfP/+222/Lkr2hLhyksWlHT9nniC65cvorE+f//1mXYA/98/7vwtCzP6p/stEq4reTxATzzBqotauHhB/iUbw6E61neWZ14gt6PB8uj5HQ1c6W7UNbAQiQX6WdQ7DVLV9hf/zYHz52/JJZ2nz5rgzEv+fOb4dnqKbLA6cWaMg++MeBqW7/b397NB7NRo4fx55vW3HUp4mhfINTI+ye63Tnl+fTsOD5XUDpCPu1BMOfPzru5VxY8HSOfHPd6fX50YZmDYv/So29GgUEXGvf6RxFmOVnE3aj9YoC+gqzOaXtC6WszWPzxbV2eUt4bO0j84k6ef+VrtLRAePz3O4YT3Bqut8cGizl9qO0A+2zzkzzOvP5KcYm8R7QQz87d4e32ltgPks2uW/ul+6yphPMD+42c4dXb2/LhrZn0A/9ox3hwY5cSZwhUhKG/6sJpYoC+gKxat2ILW+fTEE0RbIlxxcWvBfd1glNnO0BsvnD933VLS/PYDnudHn0s7QP7rF86fZ1+/mA96b3yAUJ2cM39LPnNpB8gnc6GYcrthefHjAYpZCGXt0jYa6/1fHwC8VYTcbtTV9q3dbxboC7h+eRuRcF1VTXDWe2iArs7CX0sBrrp0AQuzxgN4yZ+7rri4lWhLpKgPYo+TH6/3MD/6imiz7wNXvOTPXRcvbCR2UUtRH/SX4wmuvSy1wEghbjuA33/Ics3fUg6ljAdwF2Jftjh/RwGX2w7g5+fr5fgA7S0RLu8oXBFyu1FX88BIP1igL6CxPsS65f5MgOWHo0NnOZI46/lre13duXn6E6e9588hlae/udP7B3FoNMnrb5/x3O1vpr+/PwNXRsYn2eUxf+7q6vS+TvDYxBSvHhkq7vyxKNuLbAfIJ3uhmAuh2xkPMJosvM5veqGXIu/P3mP+zQvkNT+fef03qrQbtV8s0HtQiQWt8yllfdCuWJSD74xw4sxYus+yl/zyzPHtnhus3Fxrcecvvh0gn1cOp1YOKvb6Q6MTHDhReP7+nf2nSE5OF33+YtsB8sm1UEy5zYwHGCq478F3RnhnOFn0+1N9mhco1R7lvSLkXh+qsxu1XyzQe1CJBa3zmW3+lnzSefr4YEnrixazoHZvfKDo+dH9zNP35pj/vJBiGuTcr/jF5Mf9bPDLtVBMud1UxLxApVRESmkHyMfLQLls1y5dRFN9qGq+tZeDBXoPKrGgdT698YG887fkc81lC2mOhOiND6T7l3vJn7uuXrKQBQ3eGqx64wnWLW/zlB93ldIOkE9PPMG1Sxd5yp+7Cs0LlH3+qy5dQFvz+fO35OOuD+BHIMu1UEy5FTMeIDUQr4HYRfkH4mXzc16gnniCBY1hrrrUe0WmWrtR+8nTp11ENojIfhHpE5GHcmwXEXnY2b5TRG7M2PaEiJwQkd1+FvxCutALWudz8sw4b5wcKXr+cfeN/H/3nSgqf+4K1QnrOxcXHDg2PD7J7qOn0z11vBJx5xWa2/118+fFvr7UBFftBRfCmJg6dyH2YnTH2j23A+STb6GYC6Hbw3gAVaXn4ADdq7znxzPP77UdYDY98VRHhWIqQu71X3/7NKdGy7d+QCUVDPQiEgIeATYCa4CPiMiarN02Aqudn3uBRzO2PQls8KOwlXQhF7TOZy7rg3bHoum59UvJ73bF2nnj5AjvzDKwZfubxefHZ84/94Errx0ZKjp/nnn9d4bHib+Tf8HqPUdPM1pifryYdoB8Zlsoptzc8QA7ZxkP0D94lqOnxkr6Q1RMO0A+J8+Mc/Ck944G2ddXDW6e3kuNvgvoU9WDqpoEngY2Ze2zCXhKU14G2kRkCYCqvgDM+7t3IRe0zqc3nqCpPsS1lxW/PqgbHEpdXzTdYDXL19ve+ADhOuHGlW2ln38OH7SZ+c+L71/uJY+ezs/HynP+QorpH+43L+sTlJKfdxXTDpDPXCpC1y9vIxKqK+u0yZXkJZG5FDiS8bgf6Pawz1Lg2JxKV0XcBa3/43d3sKipfPOLzOatobPcuLJt1vlb8rlu2SIi4bqi8+eutUsX0Vhfx3/9x938xU8P5Nzn2KkxZ36g4udHv3pJauDKF/5pL1/9WV/RxwO8fXqs6Py5a9VFqQXW/+e/vM63Xozn3Of46bGC87fk47YDfPknB/jbX75Z9PEAJ86M510optwWO+MBHvv5G/zjjrdy7jMwkqStuZ5fu7jwQLxsbjvA37wY5//sKi1sJEaSNEdCXDvLRHb5uN2ov/Pymzz/+omSru+Hxc0Rvnffu3w/r5dPZK5kV3ai0cs+s19E5F5SaR9WrFhRzKEXxKKmej5z+5XsOVq+pe8KWX1JKx/tWlnSsY31If7sg2uKaiTLFAnX8dCGq2at8ay+pJXfvWlZSecP1QkPbbyK/9f3TknHu9f/0PWXlXSsiPAnG65ky/78H/LVl7Ryx9olJZ//v2y4kp/uPV7S8e7133/1JUXnv/3y6dtWs/m1o3m3rwb+zeqOcxZiL8anfms1P9jRX2LpUrpj7UV1NMh0//uu4Jmth+d0/bkq1yR1UmiQioi8C/i8qn7AefynAKr6PzL2+TqwRVW/6zzeD/ymqh5zHncCP1LVa70Uav369bpt27biX40xxtQoEdmuqutzbfPyp28rsFpEYiISAe4GNmftsxn4hNP75hbglBvkjTHGVFbBQK+qk8ADwI+BfcD3VHWPiNwnIvc5uz0HHAT6gG8An3SPF5HvAr8ErhSRfhH5I59fgzHGmFkUTN1UgqVujDGmOHNN3RhjjJnHLNAbY0zAWaA3xpiAs0BvjDEBZ4HeGGMCrip73YjISSDfOPGLgNKHT5aflW9urHxzY+Wbm/lcvpWq2pFrQ1UG+tmIyLZ8XYiqgZVvbqx8c2Plm5ugls9SN8YYE3AW6I0xJuDmY6B/vNIFKMDKNzdWvrmx8s1NIMs373L0xhhjijMfa/TGGGOKYIHeGGMCbt4EehHZICL7RaRPRB6qdHmyicghEdklIq+KSFVMvSkiT4jICRHZnfFcVER+KiK/cv4tfgHU8pbv8yLylnMfXxWROypUtuUi8ryI7BORPSLyKef5qrh/s5SvWu5fo4j0ishrTvm+4DxfLfcvX/mq4v5llDMkIjtE5EfO45Lu37zI0YtICDgA3EZqPdqtwEdUdW9FC5ZBRA4B61W1agZbiMh7gWFSC7df6zz3JSChql90/mAuVtXPVlH5Pg8Mq+r/qkSZMsq2BFiiqq+IyAJgO3AX8IdUwf2bpXz/juq4fwK0qOqwiNQDLwKfAv4t1XH/8pVvA1Vw/1wi8p+A9cBCVf1gqZ/f+VKj7wL6VPWgqiaBp4FNFS5T1VPVF4DsRV43Ad92fv82qeBQEXnKVxVU9ZiqvuL8fobUojtLqZL7N0v5qoKmDDsP650fpXruX77yVQ0RWQb8NvDNjKdLun/zJdAvBY5kPO6nit7UDgV+IiLbJbXQebW6xF3m0fn34gqXJ5cHRGSnk9qpWGrJ5ax5fAPQQxXev6zyQZXcPyft8CpwAvipqlbV/ctTPqiS+wf8JfAnwHTGcyXdv/kS6HMtK19Vf32B96jqjcBG4H4nLWGK9yhwObAOOAZ8uZKFEZFW4B+AP1bV05UsSy45ylc1909Vp1R1HbAM6BKRaytVllzylK8q7p+IfBA4oarb/TjffAn0/cDyjMfLgKMVKktOqnrU+fcE8CypdFM1Ou7kd90874kKl+ccqnrc+QBOk1p/uGL30cnd/gPwHVX9gfN01dy/XOWrpvvnUtUhYAup/HfV3D9XZvmq6P69B/iQ0/b3NPA+Efk7Srx/8yXQbwVWi0hMRCLA3cDmCpcpTURanAYxRKQFuB3YPftRFbMZ+APn9z8AfljBspzHfRM7focK3Uense5bwD5V/YuMTVVx//KVr4ruX4eItDm/NwHvB16neu5fzvJVy/1T1T9V1WWq2kkq3v1MVT9OqfdPVefFD3AHqZ43bwCfq3R5ssq2CnjN+dlTLeUDvkvq6+cEqW9FfwS0A/8K/Mr5N1pl5ftbYBew03lTL6lQ2X6dVHpwJ/Cq83NHtdy/WcpXLffvOmCHU47dwJ85z1fL/ctXvqq4f1ll/U3gR3O5f/Oie6UxxpjSzZfUjTHGmBJZoDfGmICzQG+MMQFngd4YYwLOAr0xxgScBXpjjAk4C/TGGBNw/x9DdGgHefiOaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,40), test_error, label=\"Test Error\")\n",
    "plt.legend()\n",
    "#Error goes up and down, the most trees and the error will settle down.\n",
    "#no reason to do 100 trees when it settles down around 5 anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03960396039603964,\n",
       " 0.06930693069306926,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.01980198019801982,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.01980198019801982,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991,\n",
       " 0.00990099009900991]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
